{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed to regenerate the same results\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "SEED_VALUE = 0\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED_VALUE)\n",
    "random.seed(SEED_VALUE)\n",
    "np.random.seed(SEED_VALUE)\n",
    "tf.random.set_seed(SEED_VALUE)\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from keras.preprocessing import image as kImage\n",
    "\n",
    "def fetch_data(dataset_path, target_size=(240, 320)):\n",
    "    X_img = sorted(glob.glob(os.path.join(dataset_path, 'x','*.png')))\n",
    "    Y_truth = sorted(glob.glob(os.path.join(dataset_path, 'y','*.png')))\n",
    "\n",
    "    N = len(X_img)\n",
    "    print(f\"Fetching {N} images from {dataset_path}/x\")\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for i in range(N):\n",
    "        # Load input image\n",
    "        x = kImage.load_img(X_img[i], target_size=target_size)\n",
    "        x = kImage.img_to_array(x)\n",
    "        X.append(x)\n",
    "        \n",
    "        # Load ground-truth label and encode it to label 0 and 1\n",
    "        x = kImage.load_img(Y_truth[i], target_size=target_size, color_mode = \"grayscale\")\n",
    "        x = kImage.img_to_array(x)\n",
    "        x = np.floor(x/255.0)\n",
    "        Y.append(x)\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "\n",
    "    # Shuffle the data\n",
    "    shuffled_indexes = list(range(N))\n",
    "    np.random.shuffle(shuffled_indexes)\n",
    "    X = X[shuffled_indexes]\n",
    "    Y = Y[shuffled_indexes]\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2DTranspose, Input\n",
    "\n",
    "def initModel():\n",
    "    ### Encoder\n",
    "    net_input = Input(shape=(240,320,3))\n",
    "    vgg16 = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet.h5', input_tensor=net_input)\n",
    "\n",
    "    # Make first 17 layers non-trainable\n",
    "    for layer in vgg16.layers[:17]:\n",
    "      layer.trainable = False\n",
    "    \n",
    "    x = vgg16.layers[-2].output # 2nd layer from the last, block5_conv3\n",
    "    \n",
    "    ### Decoder\n",
    "    x = Conv2DTranspose(256, (3,3), strides=(2,2), activation='relu', padding='same')(x)\n",
    "    x = Conv2DTranspose(128, (3,3), strides=(2,2), activation='relu', padding='same')(x)\n",
    "    x = Conv2DTranspose(64, (3,3), strides=(2,2), activation='relu', padding='same')(x)\n",
    "    x = Conv2DTranspose(32, (3,3), strides=(2,2), activation='relu', padding='same')(x)\n",
    "    x = Conv2DTranspose(1, (1,1), activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    model = Model(inputs=vgg16.input, outputs=x)\n",
    "\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=tf.keras.optimizers.legacy.RMSprop(learning_rate=5e-4), metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 23 images from ./dataset/train/x\n",
      "Epoch 1/100\n",
      "18/18 - 17s - loss: 0.0998 - accuracy: 0.9612 - val_loss: 0.0478 - val_accuracy: 0.9766 - lr: 5.0000e-04 - 17s/epoch - 955ms/step\n",
      "Epoch 2/100\n",
      "18/18 - 17s - loss: 0.0359 - accuracy: 0.9767 - val_loss: 0.0357 - val_accuracy: 0.9771 - lr: 5.0000e-04 - 17s/epoch - 940ms/step\n",
      "Epoch 3/100\n",
      "18/18 - 17s - loss: 0.0329 - accuracy: 0.9795 - val_loss: 0.0423 - val_accuracy: 0.9829 - lr: 5.0000e-04 - 17s/epoch - 945ms/step\n",
      "Epoch 4/100\n",
      "18/18 - 17s - loss: 0.0331 - accuracy: 0.9860 - val_loss: 0.0305 - val_accuracy: 0.9863 - lr: 5.0000e-04 - 17s/epoch - 949ms/step\n",
      "Epoch 5/100\n",
      "18/18 - 17s - loss: 0.0252 - accuracy: 0.9888 - val_loss: 0.0371 - val_accuracy: 0.9855 - lr: 5.0000e-04 - 17s/epoch - 956ms/step\n",
      "Epoch 6/100\n",
      "18/18 - 17s - loss: 0.0238 - accuracy: 0.9891 - val_loss: 0.0384 - val_accuracy: 0.9879 - lr: 5.0000e-04 - 17s/epoch - 954ms/step\n",
      "Epoch 7/100\n",
      "18/18 - 17s - loss: 0.0203 - accuracy: 0.9911 - val_loss: 0.0283 - val_accuracy: 0.9898 - lr: 5.0000e-04 - 17s/epoch - 954ms/step\n",
      "Epoch 8/100\n",
      "18/18 - 17s - loss: 0.0198 - accuracy: 0.9916 - val_loss: 0.0325 - val_accuracy: 0.9864 - lr: 5.0000e-04 - 17s/epoch - 954ms/step\n",
      "Epoch 9/100\n",
      "18/18 - 17s - loss: 0.0157 - accuracy: 0.9931 - val_loss: 0.0296 - val_accuracy: 0.9903 - lr: 5.0000e-04 - 17s/epoch - 954ms/step\n",
      "Epoch 10/100\n",
      "18/18 - 17s - loss: 0.0156 - accuracy: 0.9933 - val_loss: 0.0382 - val_accuracy: 0.9902 - lr: 5.0000e-04 - 17s/epoch - 949ms/step\n",
      "Epoch 11/100\n",
      "18/18 - 17s - loss: 0.0140 - accuracy: 0.9940 - val_loss: 0.0290 - val_accuracy: 0.9899 - lr: 5.0000e-04 - 17s/epoch - 949ms/step\n",
      "Epoch 12/100\n",
      "18/18 - 17s - loss: 0.0121 - accuracy: 0.9948 - val_loss: 0.0519 - val_accuracy: 0.9875 - lr: 5.0000e-04 - 17s/epoch - 954ms/step\n",
      "Epoch 13/100\n",
      "18/18 - 17s - loss: 0.0112 - accuracy: 0.9949 - val_loss: 0.0313 - val_accuracy: 0.9909 - lr: 5.0000e-05 - 17s/epoch - 952ms/step\n",
      "Epoch 14/100\n",
      "18/18 - 17s - loss: 0.0077 - accuracy: 0.9967 - val_loss: 0.0327 - val_accuracy: 0.9913 - lr: 5.0000e-05 - 17s/epoch - 938ms/step\n",
      "Epoch 15/100\n",
      "18/18 - 17s - loss: 0.0067 - accuracy: 0.9973 - val_loss: 0.0360 - val_accuracy: 0.9913 - lr: 5.0000e-05 - 17s/epoch - 945ms/step\n",
      "Epoch 16/100\n",
      "18/18 - 17s - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.0406 - val_accuracy: 0.9914 - lr: 5.0000e-05 - 17s/epoch - 945ms/step\n",
      "Epoch 17/100\n",
      "18/18 - 17s - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.0407 - val_accuracy: 0.9915 - lr: 5.0000e-05 - 17s/epoch - 947ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clef/Desktop/UBC/ML/SegNet/venv/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "dataset_path = \"./dataset/train\"\n",
    "X, Y = fetch_data(dataset_path)\n",
    "\n",
    "#init the model\n",
    "model = initModel()\n",
    "\n",
    "early = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10)\n",
    "reduce = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
    "\n",
    "model.fit(X, Y, batch_size=1, epochs=100, verbose=2, validation_split=0.2, callbacks=[reduce, early], shuffle=True)\n",
    "model.save('./weights/trained_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 13 images from ./dataset/test/x\n",
      "13/13 [==============================] - 9s 677ms/step\n",
      "Ran model on 13 images and got average accuracy of 98.44671474358975%\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "dataset_path = \"./dataset/test\"\n",
    "X, Y = fetch_data(dataset_path)\n",
    "\n",
    "# predict\n",
    "pred = model.predict(X, verbose=1, batch_size=1)\n",
    "\n",
    "print(f\"Ran model on {X.shape[0]} images and got average accuracy of {np.mean(np.equal(Y, np.round(pred)))*100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
